# [译]Efficient data transfer through zero copy

> https://developer.ibm.com/articles/j-zerocopy/

很多Web应用程序提供大量的静态内容，这相当于从磁盘读取数据并将完全相同的数据写回响应套接字。这个过程需要CPU参与的部分很少，但通常效率却很低：首先内核从磁盘读取数据，并将其写入内核空间，在将数据从内核空间写入到应用程序的内存空间，然后应用程序将其推回到内核空间，并将其写到socket。实际上，应用程序充当了一个低效的中介，将数据从磁盘文件获取到套接字。

每次数据传输到内核，需要CPU参数数据拷贝，消耗CPU周期和内存总线带宽。幸运的是可以通过零拷贝(尽可能的少)技术消除数据的拷贝。使用零拷贝技术的应用可以直接将数据从磁盘拷贝到socket，无需经过应用程序做中转。领拷贝技术提升了应用程序性能而且建了而下cpu在内核态和用户态的上下文切换。

Java在unix和linux系统中通过 `java.nio.channels.FileChannel`的`transferTo()`方法支持了领拷贝。通过调用`transferTo()`方法可以直接将channel的数据传输到另外一个可以写的byte channel无需应用程序做中转。本文首先演示了通过传统的复制语义进行简单的文件传输所带来的开销，然后展示了使用“transferTo()”的零拷贝技术如何获得更好的性能。

# 数据传输：传统的复制语义

考虑如下场景：读取文件数据，通过网络传播。（这个场景描述了很多服务器的行为，包括静态web服务器，FTP服务器，邮件服务器等）。核心代码包含带清单以中，包括两个函数调用。 ([download the complete sample code](http://download.boulder.ibm.com/ibmdl/pub/software/dw/java/j-zerocopy.zip)):

##### Listing 1. Copying bytes from a file to a socket

```java
File.read(fileDesc, buf, len);
Socket.send(socket, buf, len);
```

虽然清单1在概念上很简单，但是内部复制操作需要在用户模式和内核模式之间进行4次上下文切换，并且在操作完成之前要复制4次数据。图1显示了数据是如何从文件内部传输到socket的:

##### Figure 1. Traditional data copying approach

![Traditional data copying approach](https://developer.ibm.com/developer/articles/j-zerocopy/images/figure1.gif)

##### Figure 2. Traditional context switches

![Traditional context switches](https://developer.ibm.com/developer/articles/j-zerocopy/images/figure2.gif)



1. 调用`read()` 函数操内核从用户态切换到内核态(图2)。内部sys_read()(或等效)来从文件中读取数据。第一个副本(图1)由直接内存访问(DMA)引擎执行，该引擎从磁盘读取文件内容并将其存储到内核地址空间缓冲区中
2. 请求的数据从读缓冲区复制到用户缓冲区，`read()` 调用返回。调用的返回导致另一个上下文从内核切换回用户模式。现在数据存储在用户地址空间缓冲区中
3. `send()`套接字调用导致上下文从用户态切换到内核态。执行第三次复制，再次将数据放入内核地址空间缓冲区。不过，这一次，数据被放入一个不同的缓冲区，这个缓冲区与目标套接字相关联。
4. `send() `系统调用返回，导致第四次上下文切换。DMA引擎将数据从内核缓冲区传递到协议引擎，会独立地、异步地进行第四次复制。

使用中间内核缓冲区(而不是直接将数据传输到用户缓冲区)可能看起来效率很低。但是中间内核缓冲区是为了提高性能而被被引入到整个过程的。在读取端使用中间缓冲区允许内核缓冲区充当"预读缓存"。当请求的数据量小于内核缓冲区大小时，这将显著提高性能。写端上的中间缓冲区允许异步完成写操作。

不幸的是，如果请求的数据的大小远远大于内核缓冲区的大小，这种方法本身就会成为性能瓶颈。数据在最终交付给应用程序之前，会在磁盘、内核缓冲区和用户缓冲区之间复制多次。

零拷贝通过消除这些冗余的数据拷贝来提高性能。

#  数据传输：使用零拷贝

如果重新审视传统的场景，可以注意到实际上并不需要第二和第三个数据副本。应用程序只是缓存数据并将其传输回套接字缓冲区。相反，数据可以直接从读缓冲区传输到套接字缓冲区。```transferTo()```方法可以做到。清单2展示了```transferTo()```方法签名。

##### Listing 2. The transferTo() method

```java
public void transferTo(long position, long count, WritableByteChannel target);
```

The `transferTo()` method transfers data from the file channel to the given writable byte channel. Internally, it depends on the underlying operating system’s support for zero copy; in UNIX and various flavors of Linux, this call is routed to the `sendfile()` system call, shown in Listing 3, which transfers data from one file descriptor to another:

```transferTo() ```方法将数据从文件channel传输到给定的可写byte channel。在内部实现上它依赖于底层操作系统对零拷贝的支持;在UNIX和各种类型的Linux中，这个调用被路由到```sendfile() ```系统调用，如清单3所示，它将数据从一个文件描述符传输到另一个文件描述符:

##### Listing 3. The sendfile() system call

```c
#include <sys/socket.h>
ssize_t sendfile(int out_fd, int in_fd, off_t *offset, size_t count);
```

The action of the `file.read()` and `socket.send()` calls in [Listing 1](https://developer.ibm.com/articles/j-zerocopy/#listing1) can be replaced by a single `transferTo()` call, as shown in Listing 4:

清单1中的```file.read()```和```socket.send()```调用的操作可以被一个```transferTo()```调用代替，如清单4所示:

##### Listing 4. Using transferTo() to copy data from a disk file to a socket

```java
transferTo(position, count, writableChannel);
```

图3显示了使用transferTo()方法时的数据传输路径:

##### Figure 3. Data copy with transferTo()

![Data copy with transferTo()](https://developer.ibm.com/developer/articles/j-zerocopy/images/figure3.gif)

##### Figure 4. Context switching with transferTo()

![Context switching when using transferTo()](https://developer.ibm.com/developer/articles/j-zerocopy/images/figure4.gif)

1. ```transferTo() ```方法使DMA引擎将文件内容复制到一个读缓冲区中。然后内核将数据复制到与输出套接字关联的内核缓冲区中。
2. 当DMA引擎将数据从内核套接字缓冲区传递到协议引擎时，发生第三次拷贝。

这是一个改进:我们将上下文切换次数从4次降低到2次，并将数据复制的次数从4次减少到3次(其中只有一次涉及到CPU)。但这并没有让我们达到零拷贝的目标。如果底层网络接口卡支持*收集操作*，我们可以进一步减少内核所做的数据重复。在Linux内核2.4及更高版本中，修改了套接字缓冲区描述符以适应这一需求。这种方法不仅减少了多个上下文切换，还消除了需要CPU参与的重复数据副本。用户端使用仍然保持不变，但是内部特性发生了变化:

1. ```transferTo() ```方法使DMA引擎将文件内容复制到内核缓冲区中。
2. 没有数据被复制到套接字缓冲区。相反，只有包含数据位置和长度信息的描述符才会被附加到套接字缓冲区中。DMA引擎直接将数据从内核缓冲区传递到协议引擎，从而消除了剩余的最终CPU副本。

Figure 5 shows the data copies using `transferTo()` with the gather operation:

##### Figure 5. Data copies when transferTo() and gather operations are used

![Data copies when transferTo() and gather operations are used](https://developer.ibm.com/developer/articles/j-zerocopy/images/figure5.gif)

现在让我们将零拷贝付诸实践，使用client和server之间传输文件的示例(参见[Download](https://developer.ibm.com/articles/j-zerocopy/# Download)来获得示例代码)。```TraditionalClient.java```和```TraditionalServer.java```基于传统的复制语义，使用```File.read() ```和``` Socket.send() ```。```TraditionalServer.java ```是一个服务器程序，它监听一个特定端口以供client连接，然后每次从套接字中读取4K字节的数据。```TraditionalClient.java ```连接到服务器，从文件中读取(使用```file .read() ```) 4K字节的数据，并通过套接字发送(使用```socket.send() ```)内容到服务器。

同样```TransferToServer.java```和```TransferToClient.java ```执行相同的功能，但是使用```transferTo() ```方法(反过来使用```sendfile()```系统调用)将文件从服务器传输到客户端。

### Performance comparison

We executed the sample programs on a Linux system running the 2.6 kernel and measured the run time in milliseconds for both the traditional approach and the `transferTo()` approach for various sizes. Table 1 shows the results:

##### Table 1. Performance comparison: Traditional approach vs. zero copy

| File size | Normal file transfer (ms) | transferTo (ms) |
| :-------- | :------------------------ | :-------------- |
| 7MB       | 156                       | 45              |
| 21MB      | 337                       | 128             |
| 63MB      | 843                       | 387             |
| 98MB      | 1320                      | 617             |
| 200MB     | 2124                      | 1150            |
| 350MB     | 3631                      | 1762            |
| 700MB     | 13498                     | 4422            |
| 1GB       | 18399                     | 8537            |

As you can see, the `transferTo()` API brings down the time approximately 65 percent compared to the traditional approach. This has the potential to increase performance significantly for applications that do a great deal of copying of data from one I/O channel to another, such as Web servers.

## Summary

We have demonstrated the performance advantages of using `transferTo()` compared to reading from one channel and writing the same data to another. Intermediate buffer copies — even those hidden in the kernel — can have a measurable cost. In applications that do a great deal of copying of data between channels, the zero-copy technique can offer a significant performance improvement.